# server
server:
  port: 8346

spring:
  profiles:
    active: consumer
  application:
    name: spring-boot2-kafka
  # kafka

  kafka:
    # kafka 服务器地址
    bootstrap-servers: 127.0.0.1:9092,127.0.0.1:9093
    # 指定消息内容的序列化
    producer:
      # 可以单独指定生产者的 kafka 服务器地址，实现读写分离
      # bootstrap-servers:
      # 事务机制，目前与非事务方式是互斥的。
      # transaction-id-prefix: trans-
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      #      value-serializer: xyz.flysium.support.serializer.KryoSerializer
      # acks 参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的。默认 acks=1
      # acks=0 把消息发送到 kafka就认为发送成功
      # acks=1 把消息发送到 kafka leader分区，并且写入磁盘就认为发送成功
      # acks=all 把消息发送到 kafka leader分区，并且leader分区的副本follower对消息进行了同步就任务发送成功
      # 当采用事务机制，acks 必须设置为 all
      acks: 1
      # 生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误, 默认 0
      # 默认情况下，生产者会在每次重试之间等待 100ms，不过可以通过 retry.backoff.ms 参数来改变这个时间间隔。
      retries: 1
      # 设置生产者内存缓冲区的大小，单位字节数， 默认 33554432 （32MB）
      buffer-memory: 33554432
      # 指定了一个批次可以使用的内存大小，按照字节数计算（而不是消息个数）, 默认 16384 (16KB)
      batch-size: 16384
      # 压缩消息，支持四种类型，分别为：none、lz4、gzip、snappy，默认为none。
      # snappy 压缩算法由 Google 发明，它占用较少的 CPU，却能提供较好的性能和相当可观的压缩比，如果比较关注性能和网络带宽，可以使用这种算法。
      # gzip 压缩算法一般会占用较多的 CPU，但会提供更高的压缩比，所以如果网络带宽比较有限，可以使用这种算法。
      # 消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩
      compression-type: snappy
      properties:
        # transaction.timeout.ms: 60000
        # 指定了生产者在发送批次之前等待更多消息加入批次的时间, 默认情况下linger.ms=0，只要有可用的线程，生产者就会把消息发送出去，就算批次里只有一个消息。
        linger.ms: 0
        # 指定了在调用 send() 方法或使用 partitionsFor() 方法获取元数据时生产者的阻塞时间, 默认60000（60秒）
        # 当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞。
        max.block.ms: 60000
        # 生产者会在每次重试之间等待的时间间隔，默认 100 ms
        retry.backoff.ms: 100
        # 指定了生产者在收到服务器响应之前可以发送多少个消息，默认 5 。
        # 它的值越高，就会占用越多的内存，不过也会提升吞吐量。
        # 把它设为 `1` 可以保证消息是按照发送的顺序写入服务器的，即使发生了重试。
        max.in.flight.requests.per.connection: 5
        # 指定了生产者在发送数据时等待服务器返回响应的时间,默认 30000 （30秒）
        request.timeout.ms: 30000
        # 可以指定分区器，默认是org.apache.kafka.clients.producer.internals.DefaultPartitioner。在默认分区器 DefaultPartitioner 的实现中， 在 partition()方法中定义了主要的分区分配逻辑。
        # 如果 key 不为 null ，那么默认的分区器会对 key 进行哈希（采MurmurHash2 算法，具备高运算性能及低碰撞率），最终根据得到 哈希值来计算分区号，有相同 key 的消息会被写入同一个分区。
        # 如果 key null ，那么消息将会以轮询的方式发往主题内的各个可用分区。
        partitioner.class: org.apache.kafka.clients.producer.internals.DefaultPartitioner
        # 生产者拦截器，在消息被应答（ Acknowledgement ）之前或消息发送失败时调用生产者拦截器的 onAcknowledgement() 方法，优先于用户设定的 Callback 之前执行
        interceptor.classes:
        # 控制生产者发送的请求大小。它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息总的大小，默认 1048576 （1MB）
        # broker 对可接收的消息最大值也有自己的限制（message.max.bytes），所以两边的配置最好可以匹配，避免生产者发送的消息被 broker 拒绝。
        max.request.size: 1000012
        # 指定了 TCP socket 接收和发送数据包的缓冲区大小，默认 send.buffer.bytes=131072（128KB）， receive.buffer.bytes=32768（32KB）
        # 如果它们被设为 -1，就使 用操作系统的默认值。
        # 如果生产者或消费者与 broker 处于不同的数据中心，那么可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。
        send.buffer.bytes: 131072
        receive.buffer.bytes: 32768

    consumer:
      # 可以单独指定消费者的 kafka 服务器地址，实现读写分离
      # bootstrap-servers:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      #      value-deserializer: xyz.flysium.support.serializer.KryoDeserializer
      # 消费者从服务器获取记录的最小字节数, 默认为 `1` , spring boot 的 fetch-min-size 对应 kafka 消费者配置的 fetch.min.bytes
      fetch-min-size: 1
      # 指定 broker 的等待时间，默认是 500ms
      # 如果 fetch.max.wait.ms 被设为 100ms，并且 fetch.min.bytes 被设为 1MB，
      # 那么 Kafka 在收到消费者的请求后，要么返回 1MB 数据，要么在 100ms 后返回所有可用的数据，就看哪个条件先得到满足。
      fetch-max-wait: 500
      # 控制单次调用 poll() 方法能够返回的记录数量，可以帮你控制在轮询里需要处理的数据量， 默认 500
      max-poll-records: 500
      # 指定了 poll() 方法向协调器发送心跳的频率, 默认 3000 （3秒），配合参数 session.timeout.ms 一起使用
      heartbeat-interval: 3000
      # 消费者是否自动提交偏移量，默认值是 true
      # 为了尽量避免出现重复数据和数据丢失，可以把它设为  false，由自己控制何时提交偏移量。
      # 如果把它设为 true，还可以通过配置 auto.commit.interval.ms  属性来控制提交的频率。
      enable-auto-commit: false
      # 自动提交的频率(ms), 默认5000 （5秒）
      auto-commit-interval: 100
      # offset偏移量规则设置：
      # 指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时并被删除）该作何处理, 默认值是 latest
      # (1)、latest：automatically reset the offset to the latest offset
      # 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      # (2)、earliest： automatically reset the offset to the earliest offset
      # 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # (3)、none： throw exception to the consumer if no previous offset is found for the consumer's group
      # 当各分区下有已提交的offset时，从提交的offset开始消费； 只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: latest
      properties:
        # for value-deserializer: JsonDeserializer
        spring.json.trusted.packages: xyz.flysium.dao.entity
        # 决定哪些分区应该被分配给哪个消费者
        # org.apache.kafka.clients.consumer.RangeAssignor 该策略会把主题的若干个连续的分区分配给消费者。
        #         假设消费者 C1 和消费者 C2 同时订阅了主题 T1 和主题 T2，并且每个主题有 3 个分区。
        #         那么消费者 C1 有可能分配到这两个主题的分区 0 和分区 1，而消费者 C2 分配到这两个主题的分区 2。
        #         因为每个主题拥有奇数个分区，而分配是在主题内独立完成的，第一个消费者最后分配到比第二个消费者更多的分区。只
        # org.apache.kafka.clients.consumer.RoundRobinAssignor  该策略把主题的所有分区逐个分配给消费者。
        #         假设消费者 C1 和消费者 C2 同时订阅了主题 T1 和主题 T2，并且每个主题有 3 个分区。
        #         如果使用 RoundRobin 策略来给消费者 C1和消费者 C2 分配分区，那么消费者 C1 将分到主题 T1 的分区 0 和分区 2 以及主题 T2的分区 1，
        #         消费者 C2 将分配到主题 T1 的分区 1 以及主题 T2 的分区 0 和分区 2。
        partition.assignment.strategy: org.apache.kafka.clients.consumer.RangeAssignor
        # 消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 10000（10s）
        # heartbeat.interval.ms 指定了 poll() 方法向协调器发送心跳的频率，session.timeout.ms 则指定了消费者可以多久不发送心跳。
        # heartbeat.interval.ms 必须比 session.timeout.ms 小，一般是session.timeout.ms 的三分之一
        # 把 session.timeout.ms 值设得比默认值小，可以更快地检测和恢复崩溃的节点，不过长时间的轮询或垃圾收集可能导致非预期的再均衡。
        # 把 session.timeout.ms 的值设置得大一些，可以减少意外的再均衡，不过检测节点崩溃需要更长的时间。
        session.timeout.ms: 10000
        # 消费者拦截器
        #  KafkaConsumer 会在 poll()方法返回之前调用拦截器的 onConsume()方法来对消息进行相应的定制操作，
        #   比如修改返回的消息内容、按照某种规则过滤消息（可能会减少poll() 方法返回的消息的个数〉。
        #   如果 onConsume()方法中抛出异常，那么会被捕获并记录到日志中，但是异常不会再向上传递。
        #  KafkaConsumer会在提交完消费位移之后调用拦截器的 onCommit() 方法，可以使用这个方法来记录跟踪所提交的位移信息，
        #    比如当消费者使用 commitSync()  的无参方法时，我们不知道提交的消费位移的具体细节，而使用拦截器的 onCommit()方法却可以做到这一点。
        interceptor.classes:
        # 服务器从每个分区里返回给消费者的最大字节数。它的默认值是 1048576 (1MB)
        # max.partition.fetch.bytes 的值必须比 broker 能够接收的最大消息的字节数（通过 max.message.size 属性配置）大，否则消费者可能无法读取这些消息，导致消费者一直挂起重试。
        max.partition.fetch.bytes: 1000012
        # 指定了 TCP socket 接收和发送数据包的缓冲区大小，默认 send.buffer.bytes=131072（128KB）， receive.buffer.bytes=32768（32KB）
        # 如果它们被设为 -1，就使 用操作系统的默认值。
        # 如果生产者或消费者与 broker 处于不同的数据中心，那么可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。
        send.buffer.bytes: 131072
        receive.buffer.bytes: 32768

    # 加密传输
    #ssl:
    #  protocol: TLSv1.2,TLSv1.1,TLSv1
    #  trust-store-type: JKS
    #  trust-store-location:
    #  trust-store-password:
    #  key-store-type: JKS
    #  key-store-location:
    #  key-store-password:
    #  key-password:

logging:
  level:
    root: info
    org.apache.kafka.clients: INFO


